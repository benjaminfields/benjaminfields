#Throughout this project that I did in a big data class, I will be undergoing some basic operations to get used to loading, visualizing, cleaning, and running models with data. 





#Read the Data into R
library(R.utils) #Load basic necessary package
nrow=countLines("ss13hus.csv.bz2")[1] #count the number of lines in the file to understand how I will read in the data
#the data size is very large at over 7 million rows!
project1 <- "ss13hus.csv.bz2" #assign the data file a name
con <- bzfile(project1, "rt") #set up a function to read in the large data set
chunk_size=1000000 #create a maneagable chunk size to read the data in given my computer's limited RAM

#Choose a Suitable Value for chunk.size Based on Nrow
start_time <- Sys.time() #this will be combined with an a function at the end to learn how much time it took to read in all of the data
#Each of the following rows will be reading in 1,000,000 lines of data
DT1 <- read.csv(con, header=T, nrows = chunk_size)
DT2 <- read.csv(con, header=F, nrows = chunk_size)
DT3 <- read.csv(con, header=F, nrows = chunk_size)
DT4 <- read.csv(con, header=F, nrows = chunk_size)
DT5 <- read.csv(con, header=F, nrows = chunk_size)
DT6 <- read.csv(con, header=F, nrows = chunk_size)
DT7 <- read.csv(con, header=F, nrows = chunk_size)
DT8 <- read.csv(con, header=F, nrows = chunk_size)
end_time <- Sys.time()
print(end_time - start_time) #gives the completion time of reading in 7.29 million lines of data

#Extracting the Right Data Felds (REGION, ST, ADJHSG, ADJINC, NP, ACR, BDSP, ELEP, GASP, RMSP, VEH, WATP, FINCP, and HINCP)
library(dplyr) #loading necessary package
DT1 <- select(DT1,REGION, ST, ADJHSG, ADJINC, NP, ACR, BDSP, ELEP, GASP, RMSP, VEH, WATP, FINCP, HINCP)
DT2 <- select(DT2, V7, V8, V9, V10, V12, V14, V17, V21, V24, V32, V45, V46, V49, V55)
DT3 <- select(DT3, V7, V8, V9, V10, V12, V14, V17, V21, V24, V32, V45, V46, V49, V55)
DT4 <- select(DT4, V7, V8, V9, V10, V12, V14, V17, V21, V24, V32, V45, V46, V49, V55)
DT5 <- select(DT5, V7, V8, V9, V10, V12, V14, V17, V21, V24, V32, V45, V46, V49, V55)
DT6 <- select(DT6, V7, V8, V9, V10, V12, V14, V17, V21, V24, V32, V45, V46, V49, V55)
DT7 <- select(DT7, V7, V8, V9, V10, V12, V14, V17, V21, V24, V32, V45, V46, V49, V55)
DT8 <- select(DT8, V7, V8, V9, V10, V12, V14, V17, V21, V24, V32, V45, V46, V49, V55)

#Rename Column Names and Combine the Data Set
colnames(DT2) <- c("REGION", "ST", "ADJHSG", "ADJINC", "NP", "ACR", "BDSP", "ELEP", "GASP", "RMSP", "VEH", "WATP", "FINCP", "HINCP")
colnames(DT3) <- c("REGION", "ST", "ADJHSG", "ADJINC", "NP", "ACR", "BDSP", "ELEP", "GASP", "RMSP", "VEH", "WATP", "FINCP", "HINCP")
colnames(DT4) <- c("REGION", "ST", "ADJHSG", "ADJINC", "NP", "ACR", "BDSP", "ELEP", "GASP", "RMSP", "VEH", "WATP", "FINCP", "HINCP")
colnames(DT5) <- c("REGION", "ST", "ADJHSG", "ADJINC", "NP", "ACR", "BDSP", "ELEP", "GASP", "RMSP", "VEH", "WATP", "FINCP", "HINCP")
colnames(DT6) <- c("REGION", "ST", "ADJHSG", "ADJINC", "NP", "ACR", "BDSP", "ELEP", "GASP", "RMSP", "VEH", "WATP", "FINCP", "HINCP")
colnames(DT7) <- c("REGION", "ST", "ADJHSG", "ADJINC", "NP", "ACR", "BDSP", "ELEP", "GASP", "RMSP", "VEH", "WATP", "FINCP", "HINCP")
colnames(DT8) <- c("REGION", "ST", "ADJHSG", "ADJINC", "NP", "ACR", "BDSP", "ELEP", "GASP", "RMSP", "VEH", "WATP", "FINCP", "HINCP")
combinedset <- rbind(DT1,DT2)
combinedset <- rbind(combinedset,DT3)
combinedset <- rbind(combinedset,DT4)
combinedset <- rbind(combinedset,DT5)
combinedset <- rbind(combinedset,DT6)
combinedset <- rbind(combinedset,DT7)
combinedset <- rbind(combinedset,DT8)

#Creating a Subset of Data by Randomly Sampling 3,000,000 Survey Records
set.seed(1000)
data <- sample_n(combinedset, 3000000)

#Saving it as a CSV for further analysis
library("data.table")
rm(DT1)
rm(DT2)
rm(DT3)
rm(DT4)
rm(DT5)
rm(DT6)
rm(DT7)
rm(DT8)
write.csv(data,"data.csv",row.names=FALSE)

#Finding the System Time for Loading the Files
system.time(read.csv("data.csv"))
system.time(fread("data.csv"))
require(ff)
require(ffbase)
system.time(read.csv.ffdf(file = "data.csv", header=T))

#Creating a New Variable Based on FINCP and ADJINC
combinedset <- combinedset %>%
  mutate(FINCPnew = ADJINC*(FINCP/1000000))
data <- data %>%
  mutate(FINCPnew = ADJINC*(FINCP/1000000))
#data_linearmodels <- data_linearmodels %>%
#  mutate(FINCPnew = ADJINC*(FINCP/1000000))

#Create the Scatterplot of BDSP versus FINCP
library(ggplot2)
ggplot(data=data, aes(x=BDSP, y=FINCPnew)) + geom_point() + geom_smooth(method="gam")

#Settup for the Running the Loop of the Linear Models
combinedset1 <- select(combinedset, FINCPnew, BDSP, VEH)
n <- 1000
lm_answer <- c()
biglm_answer <- c()
bdspco <- c()

#Linear Model Loop
start_time2 <- Sys.time()
set.seed(2000)
for (i in 1:n){
data_linearmodels <- sample_n(combinedset, 1000000)
  lm_answer[i] <- summary(lm(FINCPnew~BDSP+VEH,data=data_linearmodels)
)$coef[2,1]
   #biglm_answer[i] <- summary(biglm(data_linearmodels))[[2]][2,1]
}
end_time2 <- Sys.time()
print(end_time2 - start_time2)

#For Big Linear Model Function
start_time3 <- Sys.time()
set.seed(3000)
for (i in 1:n){
data_linearmodels <- sample_n(combinedset, 1000000)
   biglm_answer[i] <- summary(biglm(FINCPnew~BDSP+VEH,data=data_linearmodels)
)[[2]][2,1]
}
end_time3 <- Sys.time()
print(end_time3 - start_time3)

#Mean, SD, and Density Plot for Regular LM
mean(lm_answer)
sd(lm_answer)
plot(density(lm_answer))

#Mean, SD, and Density Plot for Big LM
mean(biglm_answer)
sd(biglm_answer)
plot(density(biglm_answer))
